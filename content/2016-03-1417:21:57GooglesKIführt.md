Googles KI führt jetzt 3-0 in ihrem 5-Partien-Go-Match \...
===========================================================

Date: 2016-03-14 17:21:57

Googles KI führt jetzt 3-0 in ihrem 5-Partien-Go-Match gegen den
menschlichen Großmeister.

Ich habe nicht viel Ahnung von Go, aber ich habe mir mal ein paar
Kommentare durchgelesen. Und mein Eindruck ist, dass wir gerade eine
Zeitenwende erleben.

Bei Schach war das so, dass die Computer halt mehr Stellungen voraus
probieren konnten, und sie haben gewonnen, weil die Menschen Fehler
gemacht haben. Kommentatoren haben sich das angeguckt und konnten auf
den Zug zeigen und sagen: Das war ein Fehler. Das hat dich die Partie
gekostet.

Aber bei Go gerade ist das anders. Die KI hat eine bessere
Bewertungsfunktion als wir Menschen gefunden. Die Kommentatoren gucken
sich die Parteien an und verstehen nicht, wieso die KI gewonnen hat. Der
Mensch hat doch genau richtig gespielt! Der hat alles richtig gemacht,
und dann hat die KI diesen *komischen Zug* hier gemacht, und dann hat
der Mensch plötzlich verloren.

So, glaube ich, fühlt sich so ein Sci-Fi-Szenario an, in dem eine
überlegene außerirdische Intelligenz die Erde angreift, und wir sind
nicht schlau genug, ihre Strategie zu verstehen. Wir sehen, was sie tut,
aber wir verstehen es nicht.

Das ist übrigens auch der Grund, wieso ich neuronale Netze und KI nie
eine gute Forschungsrichtung fand. Wenn man so eine Software trainiert,
und sie tut dann Dinge, dann kann man nicht daraus lernen, was sie genau
gelernt hat, und das dann auch so tun. Man kann nur daneben sitzen und
vielleicht einzelne Perzeptronen oder so beobachten, und sich sozusagen
am Feuerwerk erfreuen, aber verstehen, was da passiert, und warum es
passiert, das geht halt nicht. Fehler debuggen geht auch nicht. Man kann
nur mehr oder neu trainieren.

Und jetzt haben wir den Salat. Glücklicherweise „nur" bei Go. Bei Go
halte ich uns Menschen für grundsätzlich in der Lage, durch Beobachtung
und Gehirnschmalz herauszuforschen, wieso wir gerade deklassiert wurden.
Aber der Weg ist sehr gefährlich, den wir da gehen.

Man stelle sich mal vor, überlegene KI wird sagen wir mal im
Gesundheitssystem eingesetzt, tut 15 mysteriöse Schritte und heilt damit
Patienten. Und hat dann Nebenwirkungen, und wir verstehen gar nicht die
Herleitung.

Oder noch schlimmer (und das halte ich für eine sehr reale Gefahr): KI
entwickelt eines Tages Software. Wir haben schon Probleme, von Menschen
geschriebene Software später zu verstehen und zu warten. Man stelle sich
mal vor, die Software tut Dinge, die keiner erklären kann, weil die von
einer KI geschrieben wurde.

Und das übelste an dem Gedankengang: Wir haben diese Art von Problem
jetzt schon, ganz ohne KI. Völlig ohne Not.

Wir sind halt doof, so als Spezies.

**Update**: Wobei, „auch so tun" kann man schon. Das war falsch
ausgedrückt. Aber verbessern kann man halt nicht. Eingreifen. Kontrolle
hat man nicht mehr. Das ist wie ein Vergleich von Ingenieur und
Kindergärtner. Man baut nichts mehr, sondern man erzieht eine KI. Wenn
die dann das richtige tut --- gut. Wenn nicht, dann hat man halt Pech.
